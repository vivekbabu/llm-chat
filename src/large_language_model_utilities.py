import os
import re
from openai import OpenAI as openai

import streamlit as st
from dotenv import load_dotenv, find_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.agents import AgentType
from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain.schema.output_parser import OutputParserException
from langchain.callbacks import StreamlitCallbackHandler


if os.environ.get('OPENAI_API_KEY') is not None:
    openai.api_key = os.environ['OPENAI_API_KEY']
else:
    _ = load_dotenv(find_dotenv())  # read local .env file
    openai.api_key = os.environ['OPENAI_API_KEY']


def chat_api(
    messages, model="gpt-4o", temperature=0.0, max_tokens=4096, top_p=0.5
):
    """
    Chat API endpoint for ChatGPT.

    Args:
        messages (str): Input messages to the chat API.
        model (str): Specifies the model (LLM) to be used.
        temperature (float): The temperature setting for response variation.
        max_tokens (int): The maximum number of tokens allowed in the response.
        top_p (float): The top-p sampling parameter.

    Returns:
        str: The response generated by the LLM.
    """
    plot_flag = False

    if any(keyword in st.session_state.messages[-1]["content"].lower() for keyword in ["plot", "graph", "draw", "chart"]):
        plot_flag = True
        code_prompt = """
                    Generate the code <code> for plotting the previous data in plotly, in the format requested. The solution should be given using plotly and only plotly. Do NOT use matplotlib.  Usage of matplotlib, matplotlib.pyplot are forbidden. Return the code <code> in the following format ```python <code>```
                    """        
        messages.append({
            "role": "assistant",
            "content": code_prompt
        })

    response = openai.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
        top_p=top_p,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None,
    )

    if plot_flag:
        code = get_python(
            response["choices"][0]["message"]["content"])
        if code is None:
            st.warning(
                "Data for plotting wasn't found in the chat. Verify if the token limit is too low for the data provided. If the generated code is incomplete, this could be the reason.",
                icon="❗"
            )
        else:
            code = code.replace("fig.show()", "")
            code += """st.plotly_chart(fig, theme='streamlit', use_container_width=True)"""
            st.write(f"```{code}")
            exec(code)

    return response["choices"][0]["message"]


def get_python(text):
    pattern = r'```python\s(.*?)```'
    matches = re.findall(pattern, text, re.DOTALL)
    if not matches:
        return None
    else:
        return matches[0]


def interact_with_data_api(df, model="gpt-4o", temperature=0.0, max_tokens=4096, top_p=0.5):
    """
    A function that answers data questions from a dataframe.
    """

    chat_client = openai()
    if any(keyword in st.session_state.messages[-1]["content"].lower() for keyword in ["plot", "graph", "draw", "chart"]):
        code_prompt = """
                    Generate the code <code> for plotting the previous data in plotly, in the format requested. The solution should be given using plotly and only plotly. Do NOT use matplotlib.  Usage of matplotlib, matplotlib.pyplot are forbidden. Return the code <code> in the following format ```python <code>```
                    """     
        conversation_history = st.session_state.messages.copy()
        conversation_history.append({
            "role": "assistant",
            "content": code_prompt
        })
        response = chat_client.chat.completions.create(
            model=model,
            messages=conversation_history,
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=top_p,
        )
        code = get_python(response.choices[0].message.content)
        with st.chat_message('assistant'):
            if code is None:
                st.warning(
                    "No data found to plot. Please verify if the token count is sufficient for the given data. "
                    "If the code appears incomplete, this could be the issue.",
                    icon="⚠️")
                return "Couldn't plot the data"
            else:
                code = code.replace("fig.show()", "")
                code += """st.plotly_chart(fig, theme='streamlit', use_container_width=True)"""  # noqa: E501
                st.write(f"```{code}")
                exec(code)
                return "Complete."
    else:
        large_lanuguage_model = ChatOpenAI(
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=top_p,
        )

        pandas_df_agent = create_pandas_dataframe_agent(
            large_lanuguage_model,
            df,
            verbose=True,
            return_intermediate_steps=True,
            agent_type=AgentType.OPENAI_FUNCTIONS,
            handle_parsing_errors=False,
            allow_dangerous_code=True,
        )
        print(st.session_state.messages)
        try:
            callback_handler = StreamlitCallbackHandler(st.container(), expand_new_thoughts=False)
            with st.chat_message('assistant'):
                pandas_df_agent_response = pandas_df_agent(st.session_state.messages, callbacks=[callback_handler])
                if pandas_df_agent_response["intermediate_steps"]:
                    last_action = pandas_df_agent_response["intermediate_steps"][-1][0].tool_input["query"]
                    with st.status("Code executed successfully."):
                        st.write(f"```{last_action}```")
                st.write(pandas_df_agent_response['output'])
                return pandas_df_agent_response["output"]
        except OutputParserException:
            error_message = """An OutputParserException occurred in the LangChain agent.
            Please refine your query."""
            return error_message
        except:
            error_message = "An unknown error occurred in the LangChain agent. Please refine your query."
            return error_message
